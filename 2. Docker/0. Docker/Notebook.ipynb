{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker\n",
    "\n",
    "<p align=center><a href=https://www.docker.com><img src=images/Docker_Logo.png width=400></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You have probably encountered an issue where the main problem is the compatibiity between the application you are running and your Operating System, or the installed packages. Wouldn't it be nice if all applications have a common ground that can be executed in any operating sytem? \n",
    "\n",
    "The solution is [Docker](https://www.docker.com), a tool that <i>container</i>ises your application so that it can ran in any environment. Containerising is the process of using containers that hold your application and all your dependencies in a single environment.\n",
    "\n",
    "This idea was an extension of LXC (Linux Containers) and their usage, and __revolutionized the way we deploy software__.\n",
    "\n",
    "__What can I use Docker for?__\n",
    "- Standardized development environment across many workstations\n",
    "- Consistent deployment of applications\n",
    "- Full reproducibility (e.g. for research)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to Containers and Images\n",
    "\n",
    "But wait... What is a container? You can think of a container as a Virtual Machine (VM), however, whilst a VM virtualises the hardware (how much RAM, memory you have), a container only virtualises the Operating System (OS). However, Docker doesn't just make a copy of the OS you want to work with, it will provide the necessary tools that will make the specific OS run. \n",
    "\n",
    "So, let's say for example that your application runs in the latest ubuntu version. Docker will NOT install the latest version each time you need to run your application, it will simply get the tools necessary to run that version without installing a whole OS. \n",
    "\n",
    "But, you might be wondering that even the tools might need a time to be installed right? That's correct, but the good thing about Docker is that it install them only once (unless you unistall it), and next time you want to run the same application, Docker will know where these tools have been installed. To do so, Docker relies on a powerful tool named Docker images, which are the templates to run containers. \n",
    "\n",
    "You can think of Docker images as Python classes, and containers as the Python instances. The image is the blueprint that indicates all the steps needed to run the container in which your application is held. The first time you `build` the image, those tools you need to run your application will be downloaded and installed, and Docker will know how to access those tools when you run you application again. \n",
    "\n",
    "One nifty trick Docker does to be more efficient is that those tools can be shared between images, so if you create another image where those tools are used again, Docker won't download or install them, because it knows how to find them.\n",
    "\n",
    "> <font size=+1>Docker allows us to package our code, apps etc. with all the necessary dependencies in a self-contained environment called a `Docker image`. We can then create instances of these images, which we call `Docker containers` </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why are containers so important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know what a container is, we can have a summary of why they are so important (and powerful)\n",
    "\n",
    "Let's see how containers changed the deployment landscape:\n",
    "\n",
    "<p align=center><img src=images/container_evolution.svg width=800></p>\n",
    "\n",
    "When deploying a regular application, the application is quite lightweight because we just deploy the code for running the applcation, but we don't (usually) have in mind the operating system that application. If we wanted, say for example, deploy the whole virtual machine, we would need to install and launch the whole operating system everytime we want to run the application. Containers takes the best of both worlds and combines the lightweightness of deploying an application the traditional way with the fact that we can take into account that it can run in multiple applications.\n",
    "\n",
    "__Benefits__:\n",
    "- Containers are more lightweight than VMs\n",
    "- They are __immutable__, meaning that their content won't change once we create the image\n",
    "- You can easily create or destroy a container whenever you need it.\n",
    "- All your application's necessities can be packed within the container\n",
    "- Containers are reproducible since they run the same everywhere, regardless of the host OS.\n",
    "- __Micro-services__ - app can be broken into multiple separate containers communicating with each other:\n",
    "    - We only change image we need\n",
    "    - No need to deploy everything a-new\n",
    "    - Easily switchable components "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Docker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important! Before starting the rest of the notebook, it is recommended to use VSCode in your local machine, since the files you will run need the Docker engine to containerise your applications locally.\n",
    "\n",
    "When creating a Docker image, your computer will need to create containers that, even though they are not VMs, they still need to allocate a memory slot (it's more complicated than `memory slots`, but for simplicity reasons, let's leave it like this) that will run certain tools that your OS might not support. \n",
    "\n",
    "In order to grant access to those memory slots, your computer needs to start an engine that creates the containers within your computer. Each OS has different ways to do so, for example, for Windows and iOS, you need to install Docker Desktop that will take care of creating the corresponding engine that will create the containers. On the other hand, Linux distributions are much more flexible, and you can run Docker just by installing the engine to create the containers.\n",
    "\n",
    "Here we are going to see how to install Docker for each OS. \n",
    "\n",
    "<details>\n",
    "    <summary> <font size=+2> For Linux Users </font> </summary>\n",
    "\n",
    "To use Docker on Linux, you need to install Docker engine, which is the core technology of Docker. To insall it, go to the following webpage and follow the [instructions](https://docs.docker.com/engine/install/centos/). There, you will find how to install Docker based on your distribution.\n",
    "\n",
    "If you are using Ubuntu, you can simply go to this [website](https://docs.docker.com/engine/install/ubuntu/). Make sure you follow the instructions that installs Docker engine `Using the repository`\n",
    "\n",
    "<p align=center> <img src=images/Docker_Engine.png width=400> </p>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary> <font size=+2>  For Mac Users and any Windows Users that doesn't have Home Edition </font> </summary>\n",
    "\n",
    "In order to use Docker on Mac, you need to install Docker Desktop. For both Mac and Windows, you can download it from this [website](https://docs.docker.com/desktop/)\n",
    "\n",
    "<p align=center> <img src=images/Docker_install.png width=400> </p>\n",
    "\n",
    "After that, select the operating system you are using. Remember that if you are using Windows Home Edition, you need to refer to the next section (in this notebook) to complete the installation.\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary> <font size=+2>  For Windows Home Edition Users </font> </summary>\n",
    "\n",
    "Unfortunatelly, Windows Home edition is the worst for installing anything that requires accessing your kernel. Luckily, there is (complicated) workaround this. You need to install the Hyper-V-Enabler, which grants permission to Docker for accessing your kernel. To download it, click this [link](https://aicore-files.s3.amazonaws.com/Foundations/Hyper-V-Enabler.bat)\n",
    "\n",
    "Then, in the Windows searchbar, look for 'Turn Windows Features On or Off', and enable the following:\n",
    "- Hyper-V Management Tools\n",
    "- Hyper-V Platform\n",
    "- Windows Hypervisor Platfor\n",
    "- Windows Subsystem for Linux\n",
    "\n",
    "<p align=center> <img src=images/Docker_Home_Edition.png width=400> </p>\n",
    "\n",
    "You also might need to install the latest version of WSL. So you can install it using the following [file](https://aicore-files.s3.amazonaws.com/Foundations/wsl_update_x64.msi)\n",
    "\n",
    "After that, follow the instructions included in the `For Mac Users and any Windows Users that doesn't have Home Edition`\n",
    "</details>\n",
    "\n",
    "For all versions, once you installed it, make sure the installation went fine by running `docker --version` in your CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have been talkin about containers and how they set up a common ground for all applications. Many other users have the images to create those containers available for the rest of the world, so everytime you need to run an application, you don't have to do it from scratch. \n",
    "\n",
    "> <font size=+1> Docker Hub is a repository that stores Docker images from users all across the world </font>\n",
    "\n",
    "You can think of Docker Hub as the GitHub for repositories, or the Pypi for Python packages. \n",
    "\n",
    "We will get more in depth with Docker Hub, but for now, let's create an account that we will eventually need to upload our images.\n",
    "\n",
    "First, go to the [Docker Hub website](https://hub.docker.com) and create an account\n",
    "\n",
    "<p align=center> <img src=images/Docker_Hub.png width=600> </p>\n",
    "\n",
    "We will go back to DockerHub later in this notebook, and you will need to sign in through your terminal, so make sure you remember the password you used!\n",
    "\n",
    "For now, one thing to bear in mind: you are going to use base images to create your own Docker images, and those base images are stored in Docker Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Images and Dockerfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font size=+1>Docker image are the instructions needed to create an instance of the Docker container</font>\n",
    "\n",
    "Thus, Docker images are essentially a set of steps that the Docker engine will take to create the environment we need to run our application. Those steps are declared in a file named `Dockerfile`, which is a special type of file that Docker will look for whenever you want to build an image. \n",
    "\n",
    "`Dockerfile` doesn't contain any extension, the name of the file is literally `Dockerfile`, but you might use it as the extension. For example, if the Dockerfile specifies the steps to create an image for an API image, you can call it `api.Dockerfile`\n",
    "\n",
    "In VSCode, when you create a Dockerfile, it will automatically recognize it as a Dockerfile, and you will notice thanks to the characteristic whale icon.\n",
    "\n",
    "<p align=center> <img src=images/Docker_icon.png width=200> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you create the Dockerfile, you can start containerising your application, but of course, you need to specify the commands you want Docker to run. \n",
    "\n",
    "Thus, let's take a look at what you can do inside a Dockerfile by looking at an example. \n",
    "\n",
    "Dockerfiles will contain instructions, such as `FROM`, `RUN`, `CMD`, `COPY`... The capitalised words starting each line in the Dockerfile are called __instructions__ and are basically commands, followed by arguments (like in terminal), which the docker build command knows how to execute. Docker build runs each of these instructions in turn to create the docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your first Docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example you will create a Docker image that runs the celebrity_births scraper you can find in the `Software Design and Testing` module. In case you haven't completed that part yet (or you forgot where you put the file), you can download the files [here](https://aicore-files.s3.amazonaws.com/Foundations/DevOps/celebrity_example.zip)\n",
    "\n",
    "After you download the file, `cd` to that folder and create the Dockerfile. Call the file `Dockerfile` and let's dive into it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the Dockerfile start writing this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "FROM python:3.8-slim-buster\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, Docker images are built from a pre-built image Docker can find on Docker Hub. The pre-built image usually contains some dependencies. For example, a common one is to use an image with Python installed. You can download and run the pre-built image using the `FROM` clause as we see above. \n",
    "\n",
    "So, with the first command we added, we will start creating our image with the necessary Python dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need is to install or copy what we want inside the docker container. Remember that the directory you add is relative to the position Dockerfile is.\n",
    "\n",
    "In your Dockerfile add the following line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "COPY . . \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will copy everything in the Dockerfile directory (`requirements.txt` and the `scraper` folder) inside the container.\n",
    "\n",
    "It's very important to understand this step. When you build the image, you are going to copy your files inside the container, and it will be like they will be in another computer. Think about the container as a separate computer where you will copy the files. So at this point, it will be like having another mini computer with Python installed and your scraper in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing you need before running the scraper is installing your python packages, like beautifulsoup and requests. Luckily, we also copied the requirements file into the image, so we can run it directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "RUN pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost there! The only thing left to do is running the python script. We can't use the `RUN` clause here, because `RUN` is executed when the image is built. We need a command that is executed when we run the image, and that clause is `CMD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CMD [\"python\", \"scraper/celebrity_scraper.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clause has many ways to be declared, in this case, we are using square brackets, and the first item is the executable (`python`) and the rest of items are the parameters (files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to build the image! In your command line interface, if you are not in the `celebrity_example` directory, move into it. Then, we need to use the `build` command from Docker. It has the following syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker build [OPTIONS] [Dockerfile path]` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the options [here](https://docs.docker.com/engine/reference/commandline/build/). One of the common options you may want to use is the -t flag, to give a `tag` to our image. That way, the image will have a name. \n",
    "\n",
    "Since we are in the same directory as the Dockerfile, the Dockerfile path is simply a dot (`.`)\n",
    "\n",
    "Run the following command in your command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:44:41.240499Z",
     "start_time": "2021-04-05T01:44:40.269Z"
    }
   },
   "outputs": [],
   "source": [
    "docker build -t celebrities:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `latest` after the name of our image is the tag (or the version if you prefer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just created our first image! Let's check if the image has been properly created by running the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:45:15.494461Z",
     "start_time": "2021-04-05T01:45:15.341555Z"
    }
   },
   "outputs": [],
   "source": [
    "docker images # show our current images on this machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=center> <img src=images/Docker_images.png width=600> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have just built an image, let's run it. We can run an image using the following syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try running our celebrities image running the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker run celebrities`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will throw an error, because the script expects an input, but right now, the image is running in a non-interactive mode. To change that, we need to add the options -i and -t. `-i` will keep the STDIN open, and `-t` will make the process interactive\n",
    "\n",
    "<p align=center> <img src=images/Docker_run_error.png width=600> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker run -it celebrities`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=center> <img src=images/Docker_run.png width=600> </p>\n",
    "\n",
    "Success! you can use this image everywhere now, regardless of the OS and dependencies installed in it. But how do you distribute it? Using Docker Hub!\n",
    "\n",
    "You have already created an account on Docker Hub, so now you can go to your command line and run:\n",
    "\n",
    "```\n",
    "docker login\n",
    "```\n",
    "\n",
    "Then enter your credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images you push to docker hub needs to have a specific name: \n",
    "```\n",
    "<username>/<image_name>:<tag>\n",
    "```\n",
    "So, let's create a copy of the existing image with a new name. We can use the docker tag command to do so. The syntax is as follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker tag <Image_Id> <New name>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image_id can be seen when you run `docker image` (See picture above), let's run the following command. In my case, my username is ivanyingx, so change that with your username, and the Image_id is 82a51cbd4876:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker tag 82a51cbd4876 ivanyingx/celebrities:v1\n",
    "```\n",
    "\n",
    "Then, you can check that the image has been properly created by running docker images again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=center> <img src=images/Docker_tag.png width=600> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, you can also check this information in the Docker Desktop if you are on Mac or Windows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=center> <img src=images/Docker_Desktop.png width=600> </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it's time to push the image to Docker Hub. Pushing an image is very similar to pushing a repository to github, simply use docker push!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker push ivanyingx/celebrities:v1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that your image has been uploaded by going to your docker hub account:\n",
    "\n",
    "<p align=center> <img src=images/Docker_Hub_example.png width=600> </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any user wants to run your container, they can do it directly running it on their local machines. For example, in this case, you can run _my_ image by running:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker pull ivanyingx/celebrities` This will download the image\n",
    "\n",
    "and then \n",
    "\n",
    "`docker run ivanyingx/celebrities` This will run the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run directly `docker run ivanyingx/celebrities`, which will perform both operations.\n",
    "\n",
    "Congratulations! You have created and pushed your first Docker image! The rest of your Docker path will consist on practicing (a lot!). The rest of the notebook dives deeper in the concepts we have seen so far, adding some commands you might find useful in the Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context & .dockerignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The build context is the set of files located at the specified PATH or URL. Those files are sent to the Docker daemon during the build so it can use them in the filesystem of the image.\" By default, the docker context is the location from which `docker build` is executed.\n",
    "\n",
    "> When we build the image in a given directory, __everything is added recursively to the context__ (so it can be copied into image, like above)\n",
    "\n",
    "`Dockerfile` might be surrounded by a lot of files and it takes time to copy them into `Docker` system (might even crash if there are too many files!)\n",
    "\n",
    "Because of that `.dockerignore` file can be specified (really similar to `.gitignore`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:44:41.245418Z",
     "start_time": "2021-04-05T01:44:40.274Z"
    }
   },
   "outputs": [],
   "source": [
    "__main__.py\n",
    "requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Containers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font size=+1>Containers are instantiations of images</font>\n",
    "\n",
    "As we have built our `repository/python_image` we can create and run container from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:44:41.248025Z",
     "start_time": "2021-04-05T01:44:40.277Z"
    }
   },
   "outputs": [],
   "source": [
    "docker run repository/python_image:latest --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking of containers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One should think of the containers as __standalone units__ (like applications) __having single responsibility__\n",
    "\n",
    "Examples could be (but are not limited to):\n",
    "- MySQL database container (other containers connect to it via `EXPOSE`d ports)\n",
    "- Data preprocessing creating a single artifact (preprocessed dataset)\n",
    "- Neural network training creating a single artifact (neural network)\n",
    "\n",
    "__Never try to fit everything into a single container!__\n",
    "\n",
    "In the above case, our container is similar to simply running `python` from the command line\n",
    "\n",
    "> Containers should be immutable (their internal state is always the same)\n",
    "\n",
    "This allows us to:\n",
    "- Destroy and recreate containers quickly\n",
    "- Always be in a well-defined state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile commands (instructions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Docker provides a couple commands, which allows us to work with in a similar fashion to command line\n",
    "\n",
    "__Each command creates a new layer__:\n",
    "- Images can be built from any layer upwards\n",
    "- __Layers are cached and reused by consecutive builds__\n",
    "- __Layers can be reused between different images__\n",
    "\n",
    "### [FROM](https://docs.docker.com/engine/reference/builder/#from)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `FROM [--platform=<platform>] <image>[:<tag>] [AS <name>]`\n",
    "\n",
    "- Starts __build stage__ of an image\n",
    "- Specifies base image (like `Ubuntu`, `node`, `conda`) which defines what one can do in the image\n",
    "- `AS` defines name for the image, we will see the usage during [multi-stage builds](https://docs.docker.com/develop/develop-images/multistage-build/).\n",
    "\n",
    "It can be mixed with `ARG` (which allows us to pass this value from a command line) like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:44:41.250268Z",
     "start_time": "2021-04-05T01:44:40.280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Version is out of build stage\n",
    "ARG VERSION=latest\n",
    "# Here build stage starts\n",
    "FROM busybox:$VERSION\n",
    "\n",
    "# Gets version into build stage\n",
    "ARG VERSION\n",
    "RUN echo $VERSION > image_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [RUN](https://docs.docker.com/engine/reference/builder/#run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Runs specified command __during build stage__ (e.g. installing some packages)\n",
    "\n",
    "Forms:\n",
    "\n",
    "> `RUN <command>` (execute via `shell`)\n",
    "\n",
    "__or__:\n",
    "\n",
    "> `RUN [\"executable\", \"param1\", \"param2\"]` (`exec` form)\n",
    "\n",
    "Which form to use?\n",
    "- `shell` - if we want to run `shell` (usually `bash`) command like `apt-get install`\n",
    "- `exec` - if the base image has no shell __or__ we don't want string munging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:44:41.252260Z",
     "start_time": "2021-04-05T01:44:40.283Z"
    }
   },
   "outputs": [],
   "source": [
    "# Equivalent\n",
    "RUN /bin/bash -c 'source $HOME/.bashrc; echo $HOME'\n",
    "RUN [\"/bin/bash\", \"-c\", \"echo hello\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Defines entrypoint (command which will be run) WHEN CONTAINER IS CREATED FROM AN IMAGE__\n",
    "\n",
    "Forms:\n",
    "\n",
    "> `ENTRYPOINT [\"executable\", \"param1\", \"param2\"]` (preferred `exec` form)\n",
    "\n",
    "__or__\n",
    "\n",
    "> `ENTRYPOINT command param1 param2` (`shell` form)\n",
    "\n",
    "- Container runs as an executable (which you should always aim to do, more on that later!)\n",
    "- You should always specify it (unless you want to use `shell`)\n",
    "- __Either of `ENTRYPOINT` or `CMD` is needed__\n",
    "\n",
    "#### `exec` form\n",
    "\n",
    "- __Does not invoke shell__, hence it is not dependent on it\n",
    "- __Allows us to use optional `CMD`__ (in a second, after command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:44:41.254678Z",
     "start_time": "2021-04-05T01:44:40.285Z"
    }
   },
   "outputs": [],
   "source": [
    "FROM ubuntu\n",
    "# When we run a container from the image, top -b will be run\n",
    "ENTRYPOINT [\"top\", \"-b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [CMD](https://docs.docker.com/engine/reference/builder/#cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Specifies default arguments to entrypoint (if any) WHICH USER CAN OVERRIDE DURING `docker run`__\n",
    "\n",
    "Forms:\n",
    "\n",
    "> `CMD [\"executable\",\"param1\",\"param2\"]` (specify `executable` as `entrypoint`, whole command can be overridden)\n",
    "\n",
    "__or__\n",
    "\n",
    "> `CMD [\"param1\",\"param2\"]` (as default parameters to ENTRYPOINT, only those could be overridden)\n",
    "\n",
    "__or__ \n",
    "\n",
    "> `CMD command param1 param2` (shell form, __discouraged__ as users is unable to override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:44:41.256857Z",
     "start_time": "2021-04-05T01:44:40.288Z"
    }
   },
   "outputs": [],
   "source": [
    "FROM ubuntu\n",
    "ENTRYPOINT [\"top\", \"-b\"]\n",
    "CMD [\"-c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we `run` the container from the above image, command `top -b -c` will be run.\n",
    "\n",
    "- `top -b` __will always run__\n",
    "- `-c` can be changed to some other flag/command via `docker run`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how `CMD` interacts with `ENTRYPOINT` for a better understanding:\n",
    "\n",
    "Note: `/bin/sh -c` is just command which executes the proceeding code in the terminal\n",
    "\n",
    "![](images/docker_entrypoint_cmd_interaction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [COPY](https://docs.docker.com/engine/reference/builder/#copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Allows users to specify which file(s) or directories should be copied into the image from host system__\n",
    "\n",
    "> `COPY <src> <destination>`\n",
    "\n",
    "Often idiom `COPY . .` is used, which copies file from context location to current working directory inside container. \n",
    "\n",
    "It might look like we're copying something to the same location, but that's not what's happening. We essentially have two file structures which we are moving files between. The file system which the first argument to `COPY` refers to is the build context (wherever you run `docker build` from). The file system which the second argument to `COPY refers to is the file system within your docker container.\n",
    "\n",
    "### Other commands\n",
    "\n",
    "There are a few others, notably:\n",
    "- `LABEL <key>=<value>` - allows us to add metadata to our image (like author, maintainer, way of contacting)\n",
    "- `WORKDIR dir` - sets working directory to a different one\n",
    "- `ENV <key>=<value>` - environment variable readable throughout the concrete build stage\n",
    "- `EXPOSE <port>` - `EXPOSE 80` would expose port `80` inside the container for others to connect (usually a person running `docker` command will specify which ports to expose and connect, hence this one isn't used very often)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands tips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Know how to use cache\n",
    "\n",
    "> __Some commands invalidate cache__ and when this happens, every step following it will have to be re-run when you create the image\n",
    "\n",
    "Let's look at the example Dockerfile below (similar to the first one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:44:41.258880Z",
     "start_time": "2021-04-05T01:44:40.293Z"
    }
   },
   "outputs": [],
   "source": [
    "FROM ubuntu:18.04\n",
    "\n",
    "RUN apt-get update\n",
    "COPY . .\n",
    "\n",
    "RUN apt-get install -y --no-install-recommends python3\n",
    "RUN rm -rf /var/lib/apt/lists/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, no matter what happens, `python3` will be installed during each `docker build`, because:\n",
    "\n",
    "> Docker has no mechanism to check whether `context` for `COPY` command changed\n",
    "\n",
    "Instead we could do what we've seen at the very beginning __as Python installation is not dependent on the context__.\n",
    "\n",
    "> __If possible, put `COPY` statements AFTER setting up OS dependencies__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain commands together\n",
    "\n",
    "> Whenever possible __chain multiple command using `&&`__ so they are all in a single `RUN` directive\n",
    "\n",
    "Docker works in a similar fashion to `git`, __it only stashes changes (additions) to the system__.\n",
    "\n",
    "This is often undesirable, because:\n",
    "- Temporary files are left out and increase image's size (`rm -rf /var/lib/apt/lists/*` seen at the beginning of the lesson)\n",
    "- Containers __are less of a black box__, which means attackers can analyze Docker system easier and find it's weak points\n",
    "\n",
    "__Main command to look out for is `RUN`, most of the commands (like `LABEL`) DO NOT create an additional layer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small, self-contained images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> __The smaller the image, the better__\n",
    "\n",
    "Imagine we have to run `10` containers from a single image published image. Now, if the image weighs `1GB` we would need to use at least `10GB` of bandwidth.\n",
    "\n",
    "Compare that to an image of `10MB`. Other pros include:\n",
    "- Smaller latency for users (setup takes considerably shorter)\n",
    "- Easier to recreate a fleet of containers (more on that during Kubernetes)\n",
    "- Easier to replace a failed container\n",
    "\n",
    "There is one killer feature of Docker which helps us achieve it, namely...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-stage builds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> First image builds the application (creating an artifact), while the second copies it and sets it up for running in a container\n",
    "\n",
    "The easiest approach is to look at an example `Dockerfile`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:44:41.261529Z",
     "start_time": "2021-04-05T01:44:40.295Z"
    }
   },
   "outputs": [],
   "source": [
    "# FIRST (BUILDER) STAGE\n",
    "FROM golang:1.7.3 AS builder\n",
    "\n",
    "# Obtain golang code\n",
    "WORKDIR /go/src/github.com/alexellis/href-counter/\n",
    "RUN go get -d -v golang.org/x/net/html  \n",
    "COPY app.go .\n",
    "# Compile is as a single exectuable file called app\n",
    "RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .\n",
    "\n",
    "# SECOND STAGE\n",
    "# alpine is a very slim file system (few MB) great for lightweight deployment\n",
    "FROM alpine:latest  \n",
    "\n",
    "# Setup only bare necessities\n",
    "RUN apk --no-cache add ca-certificates\n",
    "WORKDIR /root/\n",
    "# Copy self-contained app into the smaller image\n",
    "COPY --from=builder /go/src/github.com/alexellis/href-counter/app .\n",
    "# Setup the application as container's ENTRYPOINT\n",
    "ENTRYPOINT [\"./app\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __You should use multi-stage builds wherever possible!__\n",
    "\n",
    "### Pros\n",
    "\n",
    "- Drastically reduces image size\n",
    "- Simplifies maintenance\n",
    "\n",
    "### Cons\n",
    "\n",
    "- __Mainly usable for compilable language__ (sorry Python :( ) like Go, C++\n",
    "- __Even better with statically linked__ (e.g. everything is contained in a single executable)\n",
    "- __Hard to make it work with ML/DL__ as those require a lot of dependencies\n",
    "\n",
    "One way to go around it is to use `torchscript` and `C++` PyTorch's frontend (or neural network conversion to Tensorflow) and changing the language\n",
    "\n",
    "> Be aware, that this approach is currently really hard and might bring you a lot of headaches!\n",
    "\n",
    "> __Remember deployment is not only about neural networks, there are other things (like servers, databases etc.) that might benefit from this approach!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Online registry with many official and third party images uploaded and ready to be run as containers (or act as base)__\n",
    "\n",
    "![](images/dockerhub_main_page.png)\n",
    "\n",
    "One can `docker run` those images directly and those will be downloaded automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T12:53:25.533396Z",
     "start_time": "2021-04-05T12:53:24.367993Z"
    }
   },
   "outputs": [],
   "source": [
    "docker run busybox:latest ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips\n",
    "\n",
    "- Use official images if possible\n",
    "- Use smallest image fitting the job (e.g. `alpine` instead of `ubuntu` if possible)\n",
    "- __Check unofficial images__ (or roll out your own)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Commands\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we know a little bit about images, we may dive into Docker's command line interface.\n",
    "\n",
    "> __In new Docker version (`>=1.13`) the command line was redesigned in order to be more readable and grouped logicially__\n",
    "\n",
    "__High level most important commands__:\n",
    "- [`docker image SUBCOMMAND`](https://docs.docker.com/engine/reference/commandline/image/) - manage `Docker` images (like building or inspecting them)\n",
    "- [`docker container SUBCOMMAND`](https://docs.docker.com/engine/reference/commandline/container/) - manage `Docker` containers (creating from image, stopping, restarting, killing, inspecting etc.)\n",
    "- [`docker volume SUBCOMMAND`](https://docs.docker.com/engine/reference/commandline/volume/) - manages volumes (persistent data storage which might be shared and attached to Docker containers)\n",
    "- [`docker network SUBCOMMAND`](https://docs.docker.com/engine/reference/commandline/network/) - manage `Docker` networks (like creating, inspecting, listing etc., __not covered here, we will use Kubernetes for network related tasks__)\n",
    "\n",
    "__High level less important commands__:\n",
    "- [`docker config SUBCOMMAND`](https://docs.docker.com/engine/reference/commandline/config/) - configuration of Docker\n",
    "- [`docker stack`](https://docs.docker.com/engine/reference/commandline/stack/) - manage multiple containers as whole (__not covered, we will use Kubernetes instead__)\n",
    "- [`docker secret`](https://docs.docker.com/engine/reference/commandline/secret/) - manage secrets (like passwords and other sensitive data inside containers/images)\n",
    "- [`docker system`](https://docs.docker.com/engine/reference/commandline/system/) - manage Docker itself (how much space is used, cleaning images/containers etc.)\n",
    "\n",
    "Those `SUBCOMMAND`s are also available inside `docker` (e.g. `docker image build` is equivalent to `docker build`) and may be a source of confusion\n",
    "\n",
    "> __Check out documentation for `docker build` instead of `docker image build` as it has more information, BUT USE THE LATTER AS IT IS WAY MORE READABLE!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### docker image build\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `docker image build [OPTIONS] PATH | URL | -`\n",
    "\n",
    "As seen previously one can use it to `build` `IMAGE` from `Dockerfile` __and__ `context`.\n",
    "\n",
    "Except building from local, one can also build from:\n",
    "- `github`: `docker build github.com/creack/docker-firefox`\n",
    "- `tar.gaz`: `docker build -f ctx/Dockerfile http://server/ctx.tar.gz` (here context is on a different server)\n",
    "- From `stdin` (no context in this case): `docker build - < Dockerfile`\n",
    "\n",
    "#### Options\n",
    "\n",
    "- `-t` - tag the image (__always use it!__): `docker build -t whenry/fedora-jboss:latest -t whenry/fedora-jboss:v2.1 .` (multiple tags supported)\n",
    "- `-f` - specify different file: `docker build -f dockerfiles/Dockerfile.debug -t myapp_debug .`; __useful for separate production, testing, debugging images!__\n",
    "- `--build-arg` - pass arguments to the build stage (`ARG` above): `docker build --build-arg HTTP_PROXY=http://10.20.30.2:1234 .`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### docker container run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__The most important command you will all the time with A LOT of options!__\n",
    "\n",
    "> __REMINDER:__ \"Docker runs processes in isolated containers. A container is a process which runs on a host.\" \n",
    "\n",
    "> `docker container run [OPTIONS] IMAGE[:TAG] [COMMAND] [ARG...]`\n",
    "\n",
    "Using `OPTIONS` developer can override defaults set by the image creator, including, but not limited to:\n",
    "- detached or foreground running\n",
    "- network settings\n",
    "- runtime constraints\n",
    "- command run\n",
    "\n",
    "> `COMMAND` specifies a command to be passed to image entrypoint\n",
    "\n",
    "> `ARG` arguments passed to the command\n",
    "\n",
    "We have seen examples above\n",
    "\n",
    "#### Running container interactively\n",
    "\n",
    "> `docker container run` can attach streams (`STDIN`, `STDOUT`, `STDERR`) of container and attach a terminal so we can interact with the container\n",
    "\n",
    "- `-a NAME_OF_STREAM`\n",
    "- `-t` allocate pseudo TTY (terminal)\n",
    "- `-i` keep STDIN open even if not attached to CLI\n",
    "\n",
    "`/bin/bash` specifies the entrypoint of TTY we have attached (or attached to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options\n",
    "\n",
    "- `--name NAME` - specify name for the container (__always do this__)\n",
    "- `--rm` - remove container after exit (__usually do this__); otherwise it will prevail in your operating system not doing anything\n",
    "- `-d` - run in a detached mode (default runs in foreground, equivalent to `-d=false`)\n",
    "- `-m` - set memory limit (`docker run -it -m 300M ubuntu:14.04 /bin/bash`), there are also flags for other resources\n",
    "- `-e NAME=VALUE` - pass environment variable to the container (`export today=Wednesday; docker run -e \"deep=purple\" -e today --rm alpine env` would allow us to use `$today` inside the container)\n",
    "- `--entrypoint` - override default image entrypoint (`docker run -it --entrypoint /bin/bash example/redis`); __reset via `--entrypoint=\"\"`!__\n",
    "\n",
    "> For more check out [`docker run` reference](https://docs.docker.com/engine/reference/run/)\n",
    "\n",
    "### Exit codes\n",
    "\n",
    "> If your `docker run` fails check the return code to know where to look for bugs\n",
    "\n",
    "- `125` - error within the daemon (e.g. wrong flag passed; `docker run --foo busybox`)\n",
    "- `126` - contained comment cannot be __invoked__ (`docker run busybox /etc` - it is a directory, not a command)\n",
    "- `127` - contained comment cannot be found (`docker run busybox foo` - no command `foo`)\n",
    "\n",
    "> Otherwise return code of contained comment will be returned (usually `0` if executed correctly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker volumes\n",
    "\n",
    "We have been through a lot of content, there is one thing left... __Docker may create artifacts__ (like metrics from training or data after preprocessing).\n",
    "\n",
    "__How to get them out of container?__\n",
    "\n",
    "There are two options:\n",
    "- using `docker container cp` command\n",
    "- using volumes\n",
    "\n",
    "> __Volumes are persistent storage shared between host machine and Docker container(s)__\n",
    "\n",
    "Benefits should be obvious:\n",
    "- data sharing between containers and hosts (example: data preprocessing container creates dataset, neural network container trains our model on it)\n",
    "- we can copy to/from the containers and do the live updates of their data content\n",
    "- we can set the volume to be readable only for increased security\n",
    "\n",
    "### docker volume create\n",
    "\n",
    "> Create volume __which includes contents of the directory it was created in__\n",
    "\n",
    "(see `exercise` to check how to verify what's inside the volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker volume create docker_lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can __mount__ the volume to `/lesson` directory inside container (and list it's contents):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker container run --rm -v docker_lesson:/lesson busybox ls /lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting\n",
    "\n",
    "Let's take a look at a couple ways to `mount` the volume using `--mount`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run \\\n",
    "  --name devtest \\\n",
    "  --mount source=myvol2,target=/app \\\n",
    "  nginx:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "- Read the following aliases with comments and copy them to your aliases location\n",
    "- Run `--help` with them to know a little bit more (and check docs/google if something interests you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "alias di=\"docker image\" # General for docker images\n",
    "\n",
    "alias dib=\"docker image build\" # Build docker image\n",
    "alias dil=\"docker image ls\" # List docker images (check --help)\n",
    "alias dip=\"docker image push\" # Push NAME image\n",
    "alias dirm=\"docker image rm\" # Remove NAME image\n",
    "alias dirmall=\"docker image prune -a\" # Remove all images not used by containers\n",
    "\n",
    "# Containers\n",
    "alias dc=\"docker container\" # General for docker containers\n",
    "\n",
    "alias dcr=\"docker container run\" # Run container from an IMAGE image\n",
    "alias dccp=\"docker container cp\" # Copy data from src to dst inside container\n",
    "alias dce=\"docker container exec\" # Execute COMMAND inside container\n",
    "alias dci=\"docker container inspect\" # Inspect container\n",
    "alias dck=\"docker container kill\"  # Kill container\n",
    "alias dcl=\"docker container ls\" # List all available containers\n",
    "alias dcs=\"docker container stop\" # Stop running container\n",
    "\n",
    "alias dcrma='docker ps -a -q | xargs sudo docker rm' # Remove all non-running containers\n",
    "\n",
    "# Volumes\n",
    "alias dv=\"docker volume\" # General volume command\n",
    "\n",
    "alias dvc=\"docker volume create\" # Create NAMED volume\n",
    "alias dvl=\"docker volume ls\" # List all available volumes\n",
    "alias dvrm=\"docker volume rm\" # Remove volumes\n",
    "\n",
    "# List files inside the created volume\n",
    "dvi(){\n",
    "  docker run --rm -i -v=\"$1\":/tmp/myvolume busybox find /tmp/myvolume\n",
    "}\n",
    "\n",
    "# System\n",
    "alias dsi=\"docker system info\" # Display system-wide information\n",
    "alias dsdf=\"docker system df\" # How much images & containers take in terms of space\n",
    "alias dsp=\"docker system prune\" # Remove every unused image/containerj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash [conda env:.conda-AiCore] *",
   "language": "bash",
   "name": "conda-env-.conda-AiCore-bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
