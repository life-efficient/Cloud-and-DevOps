- create your first lambda function
  - this should be done individually
  - head over to the AWS Lambda console and click create function
  - give your function a name and select python 3.8 as a runtime
  - take a look around and explore some of the options and settings available in lambda
  - edit some of the code in your lambda function and then "deploy" it
  - click test, create a dummy test event and then test the lambda function

- run a data collection job periodically and save the data to S3
  - in the lambda editor, write the basics of what you think the function will include in the lambda function
    - try to adhere to lambda function best practices
      - where is your S3 client created?
      - is your bucket name hard-coded or set as an environment variable?
      - see more here
        - https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html
  - create a simple test in the console and run it to check the errors
  - the first major issue you should face is that you dont have the requests module
    - for this, we'll need to create a lambda layer which will contain our dependency
      - to do this, we'll need to install the python library in a folder called python, and then zip up the folder that contains that python folder
        - i.e. if you were to unzip your zipped up package, it would contain a folder called "python", which contains all of the dependency source code
        - this part can be particularly difficult to get right
  - upload this layer to AWS Lambda layers
    - dont forget to add it to your lambda function after you've created it!
  - next, you'll probably face the fact that your lambda function is missing the persmissions you need to create a file on S3
    - you'll need to create an IAM role with s3 full access permissions
      - there is no "write" only permissions like there is "read", so you should use the full access policy
      - bonus: can you restrict this policy to access only the bucket you specified, rather than all?
    - dont forget to assign it to your lambda function as the execution role!
  - you might get the error that the bucket doesnt exist. Have you created it yet?!
  - you should make sure the bucket is in the same region as your lambda function, or otherwise specify the region_name when you create the client
  - your function should be just about working now
  - head over to the cloudwatch console and find the cloudwatch rules section
  - create a new rule which triggers your lambda function every minute
  - check your S3 bucket and the last update time of the objects in there
  - success!